{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export USER=customersuccess@propelo.ai\n",
    "!export PASSWORD=\\$\\6WO85\\@\\fkhFn\n",
    "!export ENV=prod\n",
    "!export TENANT=equifax\n",
    "!export BASE_URL=https://api.levelops.io/v1/\n",
    "!export DBUSER=postgres\n",
    "!export HOST=1.1.1.1\n",
    "!export DATABASE=database\n",
    "!export DB_PASSWORD=sadhaskdjhasjkd\n",
    "!export ENV_FILE=\"prod_equifax.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "import logging\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from equifax import config as cf\n",
    "from equifax import color_grading as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_FORMAT = \"%(asctime)s %(levelname)s : %(message)s\"\n",
    "logging.basicConfig(level=logging.INFO, format=LOG_FORMAT)\n",
    "LOG = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestApiValidation:\n",
    "    path = os.path.join(\"equifax\", \"config.json\")\n",
    "    f = open(path)\n",
    "    data = json.load(f)\n",
    "    f.close()\n",
    "    tribe_ous = data[\"tribe_ous\"]\n",
    "\n",
    "    # def highlight_scope_creep(self, val):\n",
    "    #     if val == '':\n",
    "    #         color = 'yellow'\n",
    "    #         return f'background-color: {color}'\n",
    "    #     else:\n",
    "    #         color = 'red' if int(val) < 20 else 'limegreen'\n",
    "    #         return f'background-color: {color}'\n",
    "    #\n",
    "    # def highlight_commit_done(self, val):\n",
    "    #     if val == '':\n",
    "    #         color = 'yellow'\n",
    "    #         return f'background-color: {color}'\n",
    "    #     else:\n",
    "    #         color = 'red' if int(val) < 70 else 'limegreen'\n",
    "    #         return f'background-color: {color}'\n",
    "    #\n",
    "    # def highlight_predicability_range(self, val):\n",
    "    #     if val == '':\n",
    "    #         color = 'yellow'\n",
    "    #         return f'background-color: {color}'\n",
    "    #     else:\n",
    "    #         color = 'red' if int(val) < 30 else 'limegreen'\n",
    "    #         return f'background-color: {color}'\n",
    "\n",
    "    # tribe_ous=['376']\n",
    "\n",
    "    def test_all_product_lines(self, create_generic_object,\n",
    "                               widgetreusable_object):\n",
    "        print(\"testting all product lines\")\n",
    "        url = create_generic_object.connection[\"base_url\"] + self.data[\n",
    "            \"table_url\"]\n",
    "        resp = create_generic_object.execute_api_call(url=url,\n",
    "                                                      request_type='get')\n",
    "        df = pd.DataFrame()\n",
    "        flag_list = []\n",
    "        a, gt, lt = widgetreusable_object.epoch_timeStampsGenerationForRequiredTimePeriods(\n",
    "            \"LAST_MONTH\")\n",
    "\n",
    "        for i in range(0, len(resp['rows'])):\n",
    "            df1 = pd.json_normalize(resp['rows'][str(i)])\n",
    "            df = df.append(df1, ignore_index=True)\n",
    "\n",
    "        df = df.astype(str)\n",
    "        df[['total_lead_time', 'url']] = df['2'].str.split(\"]\", expand=True)\n",
    "        df['total_lead_time'] = df['total_lead_time'].str.replace(\"[\",\n",
    "                                                                  '',\n",
    "                                                                  regex=False)\n",
    "        df['url'] = df['url'].str.replace(\"(\", '', regex=False)\n",
    "        df['url'] = df['url'].str.replace(\")\", '', regex=False)\n",
    "        df = df[df['url'].notna()]\n",
    "        for i in df[\"1\"]:\n",
    "            # breakpoint()\n",
    "            print(\"OU_ID\", i)\n",
    "            if i in [\"336\", \"380\", \"55\", \"321\", \"340\", \"377\", \"379\"]:\n",
    "                continue\n",
    "            payload = cf.tribe_level_lead_time_payload(gt, lt)\n",
    "            payload['ou_ids'] = [i]\n",
    "            url1 = create_generic_object.connection[\"base_url\"] + self.data[\n",
    "                \"velocity_url\"]\n",
    "            resp_leadtime = create_generic_object.execute_api_call(\n",
    "                url=url1, data=payload, request_type=\"post\")\n",
    "            lead_df = pd.DataFrame()\n",
    "            for j in range(0, len(resp_leadtime['records'])):\n",
    "                df2 = pd.json_normalize(resp_leadtime['records'][j])\n",
    "                lead_df = lead_df.append(df2, ignore_index=True)\n",
    "            mean1 = df2['mean'].mean()\n",
    "            mean_time_convert = str(round((mean1 / 86400), 1))\n",
    "            location = df.loc[df['1'] == i].index[0]\n",
    "            total_lead_time = df.loc[location, 'total_lead_time']\n",
    "            if mean_time_convert != total_lead_time:\n",
    "                flag_list.append({\n",
    "                    \"OU_ID\": i,\n",
    "                    \"mean_time_calculated\": mean_time_convert,\n",
    "                    \"total_lead_time\": total_lead_time\n",
    "                })\n",
    "\n",
    "        # breakpoint()\n",
    "        if len(flag_list) != 0:\n",
    "            df_csv = pd.DataFrame(flag_list)\n",
    "            df_csv.to_csv(\"log_updates/\" + str(inspect.stack()[0][3]) + '.csv',\n",
    "                          header=True,\n",
    "                          index=False,\n",
    "                          mode='a')\n",
    "        assert len(\n",
    "            flag_list\n",
    "        ) == 0, f\"difference found in lead time and table---{flag_list}\"\n",
    "\n",
    "    @pytest.mark.parametrize(\"i\", tribe_ous)\n",
    "    def test_jira_releases_equifax(self, create_generic_object, i,\n",
    "                                   widgetreusable_object):\n",
    "        print(\"testting all test_jira_releases_equifax\")\n",
    "\n",
    "        release_table_report = self.data[\"release_table_report\"]\n",
    "        release_table_report_list = self.data[\"release_table_report_list\"]\n",
    "        jira_list = self.data[\"jira_list\"]\n",
    "        flag_list = []\n",
    "        a, gt, lt = widgetreusable_object.epoch_timeStampsGenerationForRequiredTimePeriods(\n",
    "            \"LAST_MONTH\")\n",
    "        release_table_report_url = create_generic_object.connection[\n",
    "            \"base_url\"] + release_table_report\n",
    "        release_table_list_url = create_generic_object.connection[\n",
    "            \"base_url\"] + release_table_report_list\n",
    "        jira_list_url = create_generic_object.connection[\"base_url\"] + jira_list\n",
    "        release_table_payload_for_tribes = cf.release_table_payload_for_tribes(\n",
    "            gt, lt)\n",
    "        velocity_list_call_payload_for_tribes = deepcopy(\n",
    "            cf.velocity_list_call_payload_for_tribes(gt, lt))\n",
    "        list_payload_release_table = cf.list_payload_release_table(gt, lt)\n",
    "\n",
    "        release_table_payload_for_tribes['ou_ids'] = [i]\n",
    "        release_names = []\n",
    "        resp_release_table = create_generic_object.execute_api_call(\n",
    "            url=release_table_report_url + \"?there_is_no_cache=true\",\n",
    "            data=release_table_payload_for_tribes,\n",
    "            request_type=\"post\")\n",
    "        for k in range(0, len(resp_release_table['records'])):\n",
    "            release_names.append(resp_release_table['records'][k]['name'])\n",
    "\n",
    "        velocity_list_call_payload_for_tribes[\"ou_ids\"] = [i]\n",
    "        LOG.info(\n",
    "            f\"velocity_list_call_payload_for_tribes-----{json.dumps(velocity_list_call_payload_for_tribes)}\"\n",
    "        )\n",
    "\n",
    "        has_next = True\n",
    "        velocity_df = pd.DataFrame()\n",
    "        page = 0\n",
    "        while has_next:\n",
    "            resp_velocity_list = create_generic_object.execute_api_call(\n",
    "                url=jira_list_url + \"?there_is_no_cache=true\",\n",
    "                data=velocity_list_call_payload_for_tribes,\n",
    "                request_type=\"post\")\n",
    "            # LOG.info(f\"resp_velocity_list---{resp_velocity_list}\")\n",
    "            has_next = resp_velocity_list['_metadata']['has_next']\n",
    "            page = page + 1\n",
    "            velocity_list_call_payload_for_tribes['page'] = page\n",
    "            velocity_df1 = pd.json_normalize(resp_velocity_list['records'],\n",
    "                                             max_level=1)\n",
    "            velocity_df = velocity_df.append(velocity_df1)\n",
    "\n",
    "        release_df = pd.DataFrame()\n",
    "        for j in release_names:\n",
    "            # breakpoint()\n",
    "            list_payload_release_table[\"ou_ids\"] = [i]\n",
    "            list_payload_release_table['filter'][\"fix_versions\"] = [j]\n",
    "            list_payload_release_table['page'] = 0\n",
    "            page = 0\n",
    "            has_next = True\n",
    "            while has_next:\n",
    "                LOG.info(\n",
    "                    f\"list_payload_release_table-----{json.dumps(list_payload_release_table)}\"\n",
    "                )\n",
    "                resp_release_table_list = create_generic_object.execute_api_call(\n",
    "                    url=release_table_list_url + \"?there_is_no_cache=true\",\n",
    "                    data=list_payload_release_table,\n",
    "                    request_type=\"post\")\n",
    "                page = page + 1\n",
    "                list_payload_release_table['page'] = page\n",
    "                has_next = resp_release_table_list['_metadata']['has_next']\n",
    "                df1 = pd.json_normalize(resp_release_table_list['records'],\n",
    "                                        max_level=1)\n",
    "                release_df = release_df.append(df1)\n",
    "\n",
    "        if len(velocity_df) != 0 and len(release_df) != 0:\n",
    "            release_key_list = release_df['key'].tolist()\n",
    "            velocity_key_list = velocity_df['key'].tolist()\n",
    "            if set(release_key_list) != set(velocity_key_list):\n",
    "                flag_list.append({\n",
    "                    \"ou_id\":\n",
    "                    i,\n",
    "                    \"Not matching keys between lead time and release table\":\n",
    "                    list(set(release_key_list) ^ set(velocity_key_list))\n",
    "                })\n",
    "\n",
    "        elif len(velocity_df) == 0:\n",
    "            if len(velocity_df) == len(release_df):\n",
    "                pass\n",
    "            else:\n",
    "                flag_list.append({\n",
    "                    f\"there is mismatch len(velocity_df)--{len(velocity_df)} and release_df---{len(release_df)} for the OU --{i}\"\n",
    "                })\n",
    "\n",
    "        assert len(flag_list) == 0, f\"flag list is not empty -----{flag_list}\"\n",
    "        LOG.info(\"Test case executed successfully\")\n",
    "\n",
    "    def test_sprint_details_equifax(self, create_generic_object,\n",
    "                                    agile_raw_data_obj, widgetreusable_object):\n",
    "        print(\"testing all  test_sprint_details_equifax\")\n",
    "        # breakpoint()\n",
    "        a, gt, lt = widgetreusable_object.epoch_timeStampsGenerationForRequiredTimePeriods(\n",
    "            \"LAST_MONTH\")\n",
    "        print(\n",
    "            \"------------------------start-test------------------------------\")\n",
    "        print(a, gt, lt)\n",
    "        sprint_details = agile_raw_data_obj.get_sprint_raw_data(gt, lt)\n",
    "        dev_prod, dora_details = agile_raw_data_obj.dev_prod_results()\n",
    "        print(dev_prod)\n",
    "        print(dora_details)\n",
    "        sprint_details = sprint_details[[\n",
    "            \"ou_name_x\", \"commit_to_done\", \"scope_creep\",\n",
    "            \"predictability_range\", \"sprint_hygiene\", \"sprint_velocity\",\n",
    "            \"lead_time_total_stories\", \"velocity/engg\"\n",
    "        ]].transpose().reset_index()\n",
    "\n",
    "        sprint_details['Goal'] = [\n",
    "            \"\", \"70%\", \"+/- 20%\", \"+/- 30%\", \"of Velocity 70%\", \"\", \"\", \"\"\n",
    "        ]\n",
    "        # breakpoint()\n",
    "        colums_list = sprint_details.columns.to_list()\n",
    "        index_pos = colums_list.index('index')\n",
    "        goal_pos = colums_list.index('Goal')\n",
    "        new_list = [colums_list[index_pos], colums_list[goal_pos]] + [\n",
    "            item for item in colums_list if item not in ['index', 'Goal']\n",
    "        ]\n",
    "\n",
    "        sprint_details = sprint_details[new_list]\n",
    "        sprint_details = sprint_details.style.applymap(\n",
    "            cm.highlight_commit_done, subset=pd.IndexSlice[1, 0:]).applymap(\n",
    "                cm.highlight_scope_creep,\n",
    "                subset=pd.IndexSlice[2, 0:]).applymap(\n",
    "                    cm.highlight_predicability_range,\n",
    "                    subset=pd.IndexSlice[3, 0:]).applymap(\n",
    "                        cm.highlight_commit_done, subset=pd.IndexSlice[4, 0:])\n",
    "\n",
    "        # sprint_details.to_excel(\"log_updates/\" + str(inspect.stack()[0][3]) + '.xlsx', engine='openpyxl', index=False,\n",
    "        #                         sheet_name=\"sprint_details\" )\n",
    "\n",
    "        dora_details = dora_details.transpose().reset_index()\n",
    "        dora_details['Goal'] = [\"\", \"4\", \"21\", \"5 %\", \"2hrs\"]\n",
    "        dora_columns = dora_details.columns.to_list()\n",
    "        index_pos = dora_columns.index('index')\n",
    "        goal_pos = dora_columns.index('Goal')\n",
    "        new_list_dora = [dora_columns[index_pos], dora_columns[goal_pos]] + [\n",
    "            item for item in dora_columns if item not in ['index', 'Goal']\n",
    "        ]\n",
    "        dora_details = dora_details[new_list_dora]\n",
    "        dora_details = dora_details.style.applymap(\n",
    "            cm.highlight_dfreq, subset=pd.IndexSlice[1, 1:]).applymap(\n",
    "                cm.highlight_leadtime, subset=pd.IndexSlice[2, 1:]).applymap(\n",
    "                    cm.highlight_cfr, subset=pd.IndexSlice[3, 1:]).applymap(\n",
    "                        cm.highlight_mttr, subset=pd.IndexSlice[4, 1:])\n",
    "\n",
    "        # dora_details.to_excel(\"log_updates/\" + str(inspect.stack()[0][3]) + '.xlsx', engine='openpyxl', index=False,\n",
    "        #                       sheet_name='dora')\n",
    "        excel_file = \"log_updates/\" + str(inspect.stack()[0][3]) + '.xlsx'\n",
    "\n",
    "        condition = (dev_prod['role'] == 'Developer')\n",
    "        condition1 = (dev_prod['role'] == 'QE')\n",
    "        condition2 = (dev_prod['role'] == 'SRE')\n",
    "        dev_prod_dev = dev_prod[condition]\n",
    "        dev_prod_QE = dev_prod[condition1]\n",
    "        dev_prod_SRE = dev_prod[condition2]\n",
    "        dev_prod_QE = dev_prod_QE[[\n",
    "            \"name\", \"role\", \"percentage of prs greater than value of roles\"\n",
    "        ]]\n",
    "        dev_prod_SRE = dev_prod_SRE[[\n",
    "            \"name\", \"role\", \"percentage of prs greater than value of roles\"\n",
    "        ]]\n",
    "        dev_prod_dev = dev_prod_dev[[\n",
    "            \"name\", \"role\", \"percentage of prs greater than value of roles\",\n",
    "            \"pr_approval_comments\", \"story_zero_to_total_devs\",\n",
    "            \"raw_stats.Average time spent working on Issues\"\n",
    "        ]]\n",
    "        dev_prod_dev_T = dev_prod_dev.transpose()\n",
    "        dev_prod_SRE_T = dev_prod_SRE.transpose()\n",
    "        dev_prod_QE_T = dev_prod_QE.transpose()\n",
    "        dev_prod_dev_T = dev_prod_dev_T.rename(\n",
    "            index={\n",
    "                \"percentage of prs greater than value of roles\":\n",
    "                \"percentage of prs greater than value of roles(DEV)\"\n",
    "            })\n",
    "        dev_prod_SRE_T = dev_prod_SRE_T.rename(\n",
    "            index={\n",
    "                \"percentage of prs greater than value of roles\":\n",
    "                \"percentage of prs greater than value of roles(SRE)\"\n",
    "            })\n",
    "        dev_prod_QE_T = dev_prod_QE_T.rename(\n",
    "            index={\n",
    "                \"percentage of prs greater than value of roles\":\n",
    "                \"percentage of prs greater than value of roles(QE)\"\n",
    "            })\n",
    "\n",
    "        # dev_prod.to_excel(\"log_updates/\" + str(inspect.stack()[0][3]) + '.xlsx', engine='openpyxl', index=False)\n",
    "\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            # Write the first DataFrame to the first sheet\n",
    "            sprint_details.to_excel(writer,\n",
    "                                    sheet_name='sprint_details',\n",
    "                                    index=False)\n",
    "\n",
    "            # Write the second DataFrame to the second sheet\n",
    "            dora_details.to_excel(writer,\n",
    "                                  sheet_name='dora_details',\n",
    "                                  index=False)\n",
    "\n",
    "            dev_prod_dev_T.to_excel(writer,\n",
    "                                    sheet_name=\"dev_details\",\n",
    "                                    index=False)\n",
    "            dev_prod_SRE_T.to_excel(writer, sheet_name=\"SRE\", index=False)\n",
    "            dev_prod_QE_T.to_excel(writer, sheet_name=\"QE\", index=False)\n",
    "\n",
    "    def test_data_validation(self, create_generic_object, agile_raw_data_obj):\n",
    "        print(\"testing all  test_data_validation\")\n",
    "        zero_prs, zero_stories, result_df = agile_raw_data_obj.data_validation(\n",
    "        )\n",
    "        styled_df = result_df.style.applymap(\n",
    "            cm.style_negative_red,\n",
    "            subset=['raw_stats.Number of stories worked on per month'\n",
    "                    ]).applymap(cm.style_negative_red,\n",
    "                                subset=['Number of PRs per month'])\n",
    "        excel_file = \"log_updates/\" + str(inspect.stack()[0][3]) + '.xlsx'\n",
    "        with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
    "            zero_prs.to_excel(writer, sheet_name='zero_prs', index=False)\n",
    "            zero_stories.to_excel(writer,\n",
    "                                  sheet_name='zero_stories',\n",
    "                                  index=False)\n",
    "            styled_df.to_excel(writer, sheet_name='raw_data', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equifax.agile_raw_data import AgileData\n",
    "from lib.generic_helper.generic_helper import TestGenericHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'aggs_get_custom_value_with_value',\n",
       " 'create_user',\n",
       " 'delete_user',\n",
       " 'execute_api_call',\n",
       " 'get_ado_custom_field',\n",
       " 'get_ado_filter_options',\n",
       " 'get_aggregration_fields',\n",
       " 'get_api_info',\n",
       " 'get_application_type_with_workspace_id',\n",
       " 'get_auth_token',\n",
       " 'get_category',\n",
       " 'get_category_ou_id',\n",
       " 'get_connect_info',\n",
       " 'get_env_based_info',\n",
       " 'get_env_var_info',\n",
       " 'get_epoc_time',\n",
       " 'get_epoc_utc',\n",
       " 'get_filter_options',\n",
       " 'get_filter_options_ado',\n",
       " 'get_filter_options_scm',\n",
       " 'get_integration_custom_details_ado',\n",
       " 'get_integration_id',\n",
       " 'get_integration_list',\n",
       " 'get_integrations_based_on_ou_id',\n",
       " 'get_jira_field_based_on_filter_type',\n",
       " 'get_org_unit_id',\n",
       " 'get_scm_filter_options',\n",
       " 'get_user_detail',\n",
       " 'get_user_detail_from_id',\n",
       " 'integration_ids_basedon_workspace',\n",
       " 'max_3_values_filter_type',\n",
       " 'rbac_user',\n",
       " 'retrieve_user_email',\n",
       " 'update_user']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(TestGenericHelper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = TestApiValidation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testting all product lines\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'TestGenericHelper' has no attribute 'connection'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test\u001b[39m.\u001b[39;49mtest_all_product_lines(TestGenericHelper,AgileData)\n",
      "\u001b[1;32m/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_all_product_lines\u001b[39m(\u001b[39mself\u001b[39m, create_generic_object,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                            widgetreusable_object):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtestting all product lines\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m     url \u001b[39m=\u001b[39m create_generic_object\u001b[39m.\u001b[39;49mconnection[\u001b[39m\"\u001b[39m\u001b[39mbase_url\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata[\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtable_url\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m     resp \u001b[39m=\u001b[39m create_generic_object\u001b[39m.\u001b[39mexecute_api_call(url\u001b[39m=\u001b[39murl,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                                                   request_type\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mget\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/prasannavaddkkepurakkal/Documents/development/prasanna/pytest-data-validation-509-equifax_data_validation/src/new.ipynb#X16sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m     df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame()\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'TestGenericHelper' has no attribute 'connection'"
     ]
    }
   ],
   "source": [
    "test.test_all_product_lines(TestGenericHelper,AgileData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from equifax import conftest as cft\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lib.generic_helper.generic_helper.TestGenericHelper"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestGenericHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
